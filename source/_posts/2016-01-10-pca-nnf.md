---
title: PCA主成分分析和NMF非负矩阵分解感悟
tags:
  - NMF
  - PCA
  - 降维
url: archives/721/index.html
id: 721
categories:
  - Default Category
date: 2016-01-10 01:41:52
---

以前只了解PCA分析，这两天看到有用非负矩阵分解NMF提取肿瘤突变特征的，遂了解了下NMF。我关注的是如何理解这两种分析，实现的话，可以找相应的R包Python包来做。

样本数：M
属性数：N
如果属性N过多话，数据存储占地方，直接分析N个属性也看不出什么，所以要降维，要研究重点。

维数由N降到X，比如降到两维

PCA分析通过分解协方差矩阵，找的是N个属性中对方差贡献靠前的X个属性，即能解释大部分variance。
样本1=0.5*属性1N1+0.2*属性1N4
样本2=0.5*属性1N2+0.2*属性2N4

NMF分析找的是X组包含对N个属性的加权值（或系数）的向量（每个属性的分解成由X个特征表示）， M*N=M*X x X*N，M*N为原始矩阵，M*X为基矩阵（每一列对应X组特征的基值），X*N为系数矩阵（每一行为一组特征）。最终还是利用了N个属性，但是利用的X组特征，每一组特征包含不同权重的N个属，X组特征共同对原始值有贡献（贡献的强度不同而已）。
样本1=0.5*特征a+0.2*特征b+0.3*特征c
样本2=0.1*特征a+0.2*特征b+0.7*特征c

PCA主要用于降维
NMF应用于非负的矩阵，一是可以降维，二还可以提取特征，看哪些特征贡献大。

参考阅读：
http://www.cnblogs.com/zhangchaoyang/articles/2222048.html
http://blog.csdn.net/acdreamers/article/details/44663421

<!--more-->

PS：

*   本文纯属杂记和感悟，此外复习了矩阵相乘，特征值和特征向量，从数学上看，如果向量v与变换满足 Av=λv，则称向量v是变换A的一个特征向量，λ是相应的特征值。几何意义，矩阵乘法对应了一个变换，是把任意一个向量变成另一个方向或长度都大多不同的新向量。在这个变换的过程中，原向量主要发生旋转、伸缩的变化。如果矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，伸缩的比例就是特征值。
*   Y=MN，N其实就是系数，Y是M通过乘系数矩阵N得到的

\#####################################################################
\#版权所有 转载请告知 版权归作者所有 如有侵权 一经发现 必将追究其法律责任
\#Author: Jason
\#####################################################################